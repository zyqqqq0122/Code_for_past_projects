{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5muMtK3HT8TG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import plotly.io as pio\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566,
     "referenced_widgets": [
      "5f5118dcd9c24d80ac6d335b813aa947",
      "263fb96f0f574bba8e3f8f6d5d018f2a",
      "9f96f65dfd2a49b4a9d879387c8d0d54",
      "849ef2c5d6534117ac010140d7c4c2cd",
      "236457b80ca74eaab660f4300bd14747",
      "3d444031bc054de395618d19abad8d09",
      "67d0cbe24b964c8c889c7077f2d72dce",
      "67e9c132de7d4883b6c5393c6da35c2c",
      "c005ee2c32ad462ba0c2e3adffa8f976",
      "feab9f9498374a2c9a3208784e2d1f8a",
      "94e9ebb36cef4af6ab00cebde2ff98a8",
      "2f26c0c21f2e49bc8bb0c35e9e06d565",
      "a557507a51d24a3b8fe1407d9c380da9",
      "6cd62ecba7b942f7be501fef7ec8bdad",
      "81428bde673746aba40af42b99c1e66f",
      "6fdd040a4d744bd89d1d514843da117c",
      "9ca9a50c8e054cb381b03f7905221adb",
      "252a988ae98f40618c71664023509f00",
      "4edbea434a6846a0a5ed9ad43dde0541",
      "3ecabce0509c4e629e03cb589976900e",
      "5f62b97aa660421d8c1ee921b50ec4a4",
      "98adf8ff61b4482c913efa9a76f8b0d4",
      "519fd47c3c4e4a8394e0d91f671e4bed",
      "ce5e98c8a7044cf0a19aeb1f47ff1fa6",
      "45695149cf564c7e82b9e9efd38edc04",
      "316977222d6840e6b484058ba7e00426",
      "0b218783f8164784b877d2b245ddac97",
      "1d7bea982dc44d53b82f7a505868db01",
      "ea1734a7c9d147fc9a99e354c5820b73",
      "88aedd54f90f4a878d29a728a91f3158",
      "7ff06ea1db0d4134914068c750ddf7db",
      "f9f91fd90b1948b69b9f27ecf4b5cbd1"
     ]
    },
    "id": "CzCokkJkUD7G",
    "outputId": "3b3e8bee-ca26-4eba-fe4b-c0d10b316ffd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'dataset'\n",
    "### With these commands the train and test datasets, respectively, are downloaded\n",
    "### automatically and stored in the local \"data_dir\" directory.\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dSuvYQ0UHwE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Set the train transform\n",
    "train_dataset.transform = train_transform\n",
    "# Set the test transform\n",
    "test_dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxDwjH65UKQ0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m=len(train_dataset)\n",
    "\n",
    "#random_split randomly split a dataset into non-overlapping new datasets of given lengths\n",
    "#train (55,000 images), val split (5,000 images)\n",
    "train_data, val_data = random_split(train_dataset, [int(m - m * 0.2), int(m * 0.2)])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# The dataloaders handle shuffling, batching, etc...\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as0xsZcPUoeB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1 Define Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5WQiiUUUkwo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim, fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            # nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            # Third convolutional layer\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            # Second linear layer\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.encoder_cnn(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # Apply linear layers\n",
    "        x = self.encoder_lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jN6C39HpUnt4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim, fc2_input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        ### Linear section\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            # Second linear layer\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        ### Unflatten\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            # First transposed convolution\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            # Second transposed convolution\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            # Third transposed convolution\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply linear layers\n",
    "        x = self.decoder_lin(x)\n",
    "        # Unflatten\n",
    "        x = self.unflatten(x)\n",
    "        # Apply transposed convolutions\n",
    "        x = self.decoder_conv(x)\n",
    "        # Apply a sigmoid to force the output to be between 0 and 1 (valid pixel values)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqAEQg_OUxS6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2 Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm-x0O_pob3Q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_noise(inputs, noise_factor=0.3):\n",
    "     noise = inputs + torch.randn_like(inputs) * noise_factor\n",
    "     noise = torch.clip(noise, 0., 1.)\n",
    "     return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Compute covariance\n",
    "def cov_cpt(img):\n",
    "    # img = img.detach().cpu().numpy()\n",
    "    cov_out = torch.zeros((len(img), img.shape[2], img.shape[3]))\n",
    "    for ii in range(len(img)):\n",
    "        pic = img[ii][0]\n",
    "        cov_img = torch.cov(pic) # (28, 28)\n",
    "        cov_out[ii] = cov_img\n",
    "\n",
    "    return cov_out # (256,28, 28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_ae_outputs_den(encoder,decoder,n=5,noise_factor=0.3):\n",
    "    plt.figure(figsize=(10,4.5))\n",
    "    for i in range(n):\n",
    "\n",
    "      ax = plt.subplot(3,n,i+1)\n",
    "      img = test_dataset[i][0].unsqueeze(0)\n",
    "      image_noisy = add_noise(img,noise_factor)     \n",
    "      image_noisy = image_noisy.to(device)\n",
    "\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "         rec_img = decoder(encoder(image_noisy))\n",
    "\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(3, n, i + 1 + n)\n",
    "      plt.imshow(image_noisy.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Corrupted images')\n",
    "\n",
    "      ax = plt.subplot(3, n, i + 1 + n + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.7, \n",
    "                    top=0.9, \n",
    "                    wspace=0.3, \n",
    "                    hspace=0.3)     \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_train_loss(train_loss, train_loss_x, train_loss_z):\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.plot(range(len(train_loss)), train_loss, label='train_loss') \n",
    "    ax.plot(range(len(train_loss_x)), train_loss_x, label='train_loss_x') \n",
    "    ax.plot(range(len(train_loss_z)), train_loss_z, label='train_loss_z')\n",
    "    ax.set_xlabel('Training epoch') \n",
    "    ax.set_ylabel('Loss') \n",
    "    ax.legend() \n",
    "\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_train_val_loss(train_loss, val_loss):\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.plot(range(len(train_loss)), train_loss, label='train_loss') \n",
    "    ax.plot(range(len(val_loss)), val_loss, label='val_loss') \n",
    "\n",
    "    ax.set_xlabel('Epochs') \n",
    "    ax.set_ylabel('Loss') \n",
    "    ax.legend() \n",
    "    plt.show() \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Non-feedback model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "### Initialize the two networks\n",
    "d = 4\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr= 0.001 # Learning rate\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfrLl5_qUKbd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training function\n",
    "from email.mime import image\n",
    "\n",
    "\n",
    "def train_epoch_den(encoder, decoder, device, dataloader, loss_fn, optimizer,noise_factor=0.3):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_noisy = add_noise(image_batch,noise_factor)\n",
    "        image_noisy = image_noisy.to(device)    \n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_noisy)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Compute covariance\n",
    "        c_x = cov_cpt(image_noisy)\n",
    "        c_x_bar = cov_cpt(decoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(c_x, c_x_bar)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        # print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWM89AYgUKeM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch_den(encoder, decoder, device, dataloader, loss_fn,noise_factor=0.3):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for image_batch, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_noisy = add_noise(image_batch,noise_factor)\n",
    "            image_noisy = image_noisy.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_noisy)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C891gOpYVN_1",
    "outputId": "16f09fa2-4835-4987-a3f7-e9ac4916e51a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 10\n",
    "history_da={'train_loss':[],'val_loss':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training (use the training function)\n",
    "    train_loss=train_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_loader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ae_outputs_den(encoder,decoder,noise_factor=noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIAq-oOpVODM",
    "outputId": "5e1248f3-deb4-4183-d5b3-5084e6592e90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res=test_epoch_den(encoder,decoder,device,test_loader,loss_fn)\n",
    "print(res.item())\n",
    "result.append({'lambda_x':1, 'lambda_z':0, 'test_loss':res.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_train_val_loss(history_da['train_loss'], history_da['val_loss'])\n",
    "# fig.savefig('fig/covariance_1_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Feedback model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.2.1 $\\mathcal{L}=\\|C_x-C_{\\hat{x}}\\|_{F}^{2}+\\lambda\\|z-\\hat{z}\\|_{2}^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch_den(encoder, decoder, device, dataloader, loss_fn, optimizer, para, noise_factor=0.3):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    train_loss_x = []\n",
    "    train_loss_z = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_noisy = add_noise(image_batch,noise_factor)\n",
    "        image_noisy = image_noisy.to(device)    \n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_noisy)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Feedback data\n",
    "        feedback_data = encoder(decoded_data)\n",
    "        # Evaluate loss\n",
    "        c_x = cov_cpt(image_noisy)\n",
    "        c_x_bar = cov_cpt(decoded_data)\n",
    "        \n",
    "        loss_x = loss_fn(c_x, c_x_bar)\n",
    "        loss_z = loss_fn(feedback_data, encoded_data)\n",
    "        \n",
    "        loss = loss_x + para * loss_z\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        # print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "        train_loss_x.append(loss_x.detach().cpu().numpy())\n",
    "        train_loss_z.append(loss_z.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss), np.mean(train_loss_x), np.mean(train_loss_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch_den(encoder, decoder, device, dataloader, loss_fn,noise_factor=0.3):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for image_batch, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_noisy = add_noise(image_batch,noise_factor)\n",
    "            image_noisy = image_noisy.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_noisy)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$\\lambda=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "### Initialize the two networks\n",
    "d = 4\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr= 0.001 # Learning rate\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 10\n",
    "para = 1\n",
    "history_da={'train_loss':[], 'val_loss':[], 'train_loss_x':[], 'train_loss_z':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training (use the training function)\n",
    "    train_loss, train_loss_x, train_loss_z=train_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_loader, \n",
    "        loss_fn=loss_fn, \n",
    "        para=para,\n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['train_loss_x'].append(train_loss_x)\n",
    "    history_da['train_loss_z'].append(train_loss_z)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.5f} \\t val loss {:.5f} \\t train loss x {:.5f} \\t train loss z {:.5f}'.format(epoch + 1, num_epochs,train_loss,val_loss,train_loss_x,train_loss_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ae_outputs_den(encoder,decoder,noise_factor=noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res=test_epoch_den(encoder,decoder,device,test_loader,loss_fn)\n",
    "print(res.item())\n",
    "result.append({'lambda_x':1, 'lambda_z':para, 'test_loss':res.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_train_val_loss(history_da['train_loss'], history_da['val_loss'])\n",
    "# fig.savefig('fig/covariance_1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_loss(history_da['train_loss'], history_da['train_loss_x'], history_da['train_loss_z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$\\lambda=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "### Initialize the two networks\n",
    "d = 4\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr= 0.001 # Learning rate\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 10\n",
    "para = 0.5\n",
    "history_da={'train_loss':[], 'val_loss':[], 'train_loss_x':[], 'train_loss_z':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training (use the training function)\n",
    "    train_loss, train_loss_x, train_loss_z=train_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_loader, \n",
    "        loss_fn=loss_fn, \n",
    "        para=para,\n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['train_loss_x'].append(train_loss_x)\n",
    "    history_da['train_loss_z'].append(train_loss_z)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.5f} \\t val loss {:.5f} \\t train loss x {:.5f} \\t train loss z {:.5f}'.format(epoch + 1, num_epochs,train_loss,val_loss,train_loss_x,train_loss_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ae_outputs_den(encoder,decoder,noise_factor=noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res=test_epoch_den(encoder,decoder,device,test_loader,loss_fn)\n",
    "print(res.item())\n",
    "result.append({'lambda_x':1, 'lambda_z':para, 'test_loss':res.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_train_val_loss(history_da['train_loss'], history_da['val_loss'])\n",
    "# fig.savefig('fig/covariance_1_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_loss(history_da['train_loss'], history_da['train_loss_x'], history_da['train_loss_z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$\\lambda=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "### Initialize the two networks\n",
    "d = 4\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr= 0.001 # Learning rate\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 10\n",
    "para = 2\n",
    "history_da={'train_loss':[], 'val_loss':[], 'train_loss_x':[], 'train_loss_z':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training (use the training function)\n",
    "    train_loss, train_loss_x, train_loss_z=train_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_loader, \n",
    "        loss_fn=loss_fn, \n",
    "        para=para,\n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['train_loss_x'].append(train_loss_x)\n",
    "    history_da['train_loss_z'].append(train_loss_z)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.5f} \\t val loss {:.5f} \\t train loss x {:.5f} \\t train loss z {:.5f}'.format(epoch + 1, num_epochs,train_loss,val_loss,train_loss_x,train_loss_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ae_outputs_den(encoder,decoder,noise_factor=noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res=test_epoch_den(encoder,decoder,device,test_loader,loss_fn)\n",
    "print(res.item())\n",
    "result.append({'lambda_x':1, 'lambda_z':para, 'test_loss':res.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_train_val_loss(history_da['train_loss'], history_da['val_loss'])\n",
    "# fig.savefig('fig/covariance_1_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_loss(history_da['train_loss'], history_da['train_loss_x'], history_da['train_loss_z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.2.2 $\\mathcal{L}=\\lambda\\|x-\\hat{x}\\|_{2}^{2}+\\|z-\\hat{z}\\|_{2}^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch_den(encoder, decoder, device, dataloader, loss_fn, optimizer, para, noise_factor=0.3):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    train_loss_x = []\n",
    "    train_loss_z = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_noisy = add_noise(image_batch,noise_factor)\n",
    "        image_noisy = image_noisy.to(device)    \n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_noisy)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Feedback data\n",
    "        feedback_data = encoder(decoded_data)\n",
    "        # Evaluate loss\n",
    "        c_x = cov_cpt(image_noisy)\n",
    "        c_x_bar = cov_cpt(decoded_data)\n",
    "        \n",
    "        loss_x = loss_fn(c_x, c_x_bar)\n",
    "        loss_z = loss_fn(feedback_data, encoded_data)\n",
    "        \n",
    "        loss = para * loss_x + loss_z\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        # print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "        train_loss_x.append(loss_x.detach().cpu().numpy())\n",
    "        train_loss_z.append(loss_z.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss), np.mean(train_loss_x), np.mean(train_loss_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$\\lambda=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "### Initialize the two networks\n",
    "d = 4\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr= 0.001 # Learning rate\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 10\n",
    "para = 0.5\n",
    "history_da={'train_loss':[], 'val_loss':[], 'train_loss_x':[], 'train_loss_z':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training (use the training function)\n",
    "    train_loss, train_loss_x, train_loss_z=train_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_loader, \n",
    "        loss_fn=loss_fn, \n",
    "        para=para,\n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['train_loss_x'].append(train_loss_x)\n",
    "    history_da['train_loss_z'].append(train_loss_z)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.5f} \\t val loss {:.5f} \\t train loss x {:.5f} \\t train loss z {:.5f}'.format(epoch + 1, num_epochs,train_loss,val_loss,train_loss_x,train_loss_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ae_outputs_den(encoder,decoder,noise_factor=noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res=test_epoch_den(encoder,decoder,device,test_loader,loss_fn)\n",
    "print(res.item())\n",
    "result.append({'lambda_x':para, 'lambda_z':1, 'test_loss':res.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_train_val_loss(history_da['train_loss'], history_da['val_loss'])\n",
    "# fig.savefig('fig/covariance_05_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_loss(history_da['train_loss'], history_da['train_loss_x'], history_da['train_loss_z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_x</th>\n",
       "      <th>lambda_z</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.312755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.321387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.309205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda_x  lambda_z  test_loss\n",
       "0       1.0       0.0   0.348588\n",
       "1       1.0       1.0   0.312755\n",
       "2       1.0       0.5   0.321387\n",
       "3       1.0       2.0   0.309205\n",
       "4       0.5       1.0   0.305212"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "denAE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b218783f8164784b877d2b245ddac97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88aedd54f90f4a878d29a728a91f3158",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea1734a7c9d147fc9a99e354c5820b73",
      "value": 4542
     }
    },
    "1d7bea982dc44d53b82f7a505868db01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9f91fd90b1948b69b9f27ecf4b5cbd1",
      "placeholder": "",
      "style": "IPY_MODEL_7ff06ea1db0d4134914068c750ddf7db",
      "value": " 5120/? [00:00&lt;00:00, 29647.70it/s]"
     }
    },
    "236457b80ca74eaab660f4300bd14747": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "252a988ae98f40618c71664023509f00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "263fb96f0f574bba8e3f8f6d5d018f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f26c0c21f2e49bc8bb0c35e9e06d565": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fdd040a4d744bd89d1d514843da117c",
      "placeholder": "",
      "style": "IPY_MODEL_81428bde673746aba40af42b99c1e66f",
      "value": " 29696/? [00:49&lt;00:00, 605.30it/s]"
     }
    },
    "316977222d6840e6b484058ba7e00426": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d444031bc054de395618d19abad8d09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ecabce0509c4e629e03cb589976900e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce5e98c8a7044cf0a19aeb1f47ff1fa6",
      "placeholder": "",
      "style": "IPY_MODEL_519fd47c3c4e4a8394e0d91f671e4bed",
      "value": " 1649664/? [00:48&lt;00:00, 33725.93it/s]"
     }
    },
    "45695149cf564c7e82b9e9efd38edc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b218783f8164784b877d2b245ddac97",
       "IPY_MODEL_1d7bea982dc44d53b82f7a505868db01"
      ],
      "layout": "IPY_MODEL_316977222d6840e6b484058ba7e00426"
     }
    },
    "4edbea434a6846a0a5ed9ad43dde0541": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98adf8ff61b4482c913efa9a76f8b0d4",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f62b97aa660421d8c1ee921b50ec4a4",
      "value": 1648877
     }
    },
    "519fd47c3c4e4a8394e0d91f671e4bed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f5118dcd9c24d80ac6d335b813aa947": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f96f65dfd2a49b4a9d879387c8d0d54",
       "IPY_MODEL_849ef2c5d6534117ac010140d7c4c2cd"
      ],
      "layout": "IPY_MODEL_263fb96f0f574bba8e3f8f6d5d018f2a"
     }
    },
    "5f62b97aa660421d8c1ee921b50ec4a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "67d0cbe24b964c8c889c7077f2d72dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67e9c132de7d4883b6c5393c6da35c2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cd62ecba7b942f7be501fef7ec8bdad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fdd040a4d744bd89d1d514843da117c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ff06ea1db0d4134914068c750ddf7db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81428bde673746aba40af42b99c1e66f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "849ef2c5d6534117ac010140d7c4c2cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67e9c132de7d4883b6c5393c6da35c2c",
      "placeholder": "",
      "style": "IPY_MODEL_67d0cbe24b964c8c889c7077f2d72dce",
      "value": " 9913344/? [05:12&lt;00:00, 31749.39it/s]"
     }
    },
    "88aedd54f90f4a878d29a728a91f3158": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94e9ebb36cef4af6ab00cebde2ff98a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd62ecba7b942f7be501fef7ec8bdad",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a557507a51d24a3b8fe1407d9c380da9",
      "value": 28881
     }
    },
    "98adf8ff61b4482c913efa9a76f8b0d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ca9a50c8e054cb381b03f7905221adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4edbea434a6846a0a5ed9ad43dde0541",
       "IPY_MODEL_3ecabce0509c4e629e03cb589976900e"
      ],
      "layout": "IPY_MODEL_252a988ae98f40618c71664023509f00"
     }
    },
    "9f96f65dfd2a49b4a9d879387c8d0d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d444031bc054de395618d19abad8d09",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_236457b80ca74eaab660f4300bd14747",
      "value": 9912422
     }
    },
    "a557507a51d24a3b8fe1407d9c380da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c005ee2c32ad462ba0c2e3adffa8f976": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94e9ebb36cef4af6ab00cebde2ff98a8",
       "IPY_MODEL_2f26c0c21f2e49bc8bb0c35e9e06d565"
      ],
      "layout": "IPY_MODEL_feab9f9498374a2c9a3208784e2d1f8a"
     }
    },
    "ce5e98c8a7044cf0a19aeb1f47ff1fa6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea1734a7c9d147fc9a99e354c5820b73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f9f91fd90b1948b69b9f27ecf4b5cbd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feab9f9498374a2c9a3208784e2d1f8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}