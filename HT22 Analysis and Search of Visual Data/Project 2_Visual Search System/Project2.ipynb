{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Project 2: Visual Search System\n",
    "### 1 Image Feature Extraction\n",
    "#### (a) Extract 2000 SIFT features from 149 database images with each of 50 different buildings appearing in 2,3 or 4 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Import image\n",
    "img_dir = 'server'\n",
    "img_list = os.listdir(img_dir)\n",
    "img_list.sort(key=lambda x: int((x.split('_')[0])[3:]))\n",
    "\n",
    "# To match number of object and index of list, des_all[0] is empty and\n",
    "# descriptors of object i are in des_all[i]\n",
    "des_all = [[] for i in range(51)]\n",
    "nfeature = 2000\n",
    "for i in range(len(img_list)):\n",
    "\n",
    "    obj = int((img_list[i].split('_')[0])[3:])\n",
    "\n",
    "    img_path = os.path.join(img_dir, img_list[i])\n",
    "    img = cv.imread(img_path)\n",
    "\n",
    "    # Extract 3000 feature vectors from each image\n",
    "    sift = cv.xfeatures2d.SIFT_create(nfeatures=nfeature, contrastThreshold=0.05, edgeThreshold=10)\n",
    "    _, des = sift.detectAndCompute(img, None)\n",
    "    if des.shape[0] < nfeature:\n",
    "        print(\"Warning\")\n",
    "    des_all[obj].append(des)\n",
    "\n",
    "# Adjust des_all to a matrix where each row represents a feature descriptor, with the label of object attached to the last element of the descriptor\n",
    "database = np.zeros((nfeature*149, 129))\n",
    "base_label = np.zeros(nfeature*149)\n",
    "k = 0\n",
    "for i in range(1, 51):\n",
    "    des_obj = des_all[i]\n",
    "    for j in range(len(des_obj)):\n",
    "        des_one = des_obj[j]\n",
    "        for m in range(nfeature):\n",
    "            database[k, :128] = des_one[m, :]\n",
    "            database[k, -1] = i\n",
    "            k += 1\n",
    "\n",
    "# Save database data to file using pickle\n",
    "file = open('database.txt', 'wb')\n",
    "pickle.dump(database, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) Extract 2000 SIFT features from 50 query images of 50 different buildings, and save the data to folder Query_des"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "### Extract and save features of clients\n",
    "nfeature = 2000\n",
    "sift = cv.xfeatures2d.SIFT_create(nfeatures=nfeature, contrastThreshold=0.05, edgeThreshold=10)\n",
    "nof = np.zeros(50)\n",
    "for s in range(1, 51):\n",
    "    im_path = 'client/'+'obj'+str(s)+'_t1.JPG'\n",
    "    im = cv.imread(im_path)\n",
    "    _, des = sift.detectAndCompute(im, None)\n",
    "    nof[s-1] = des.shape[0]\n",
    "    with open('./Query_des/des_client{}.pkl'.format(s), 'wb') as f:\n",
    "            pickle.dump(des, f, pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 Vocabulary Tree Construction\n",
    "#### Recursively build the vocabulary tree which separate the 2000*149 feature vectors into #b to the power of #depth number of clusters a.k.a. visual vocabularies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hi_kmeans(data, b, depth, icenter, ileaf, center):\n",
    "    '''\n",
    "    :param data: The SIFT features from the database objects\n",
    "    :param b: The branch number of vocabulary tree\n",
    "    :param depth: The number of levels of the vocabulary tree\n",
    "    :param icenter: The center of all clusters that is divided in every level\n",
    "    :param ileaf: The leaf nodes a.k.a. visual vocabularies of the tree\n",
    "    :param center: A temporary variable to store the centers of the clusters grown by a father cluster\n",
    "    :return: icenter, ileaf\n",
    "    '''\n",
    "    if depth > 0:\n",
    "        if data.shape[0] < b:\n",
    "            icenter.append(center)\n",
    "            for cnt in range(b):\n",
    "                hi_kmeans(data, b, depth - 1, icenter, ileaf, center)\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=b, random_state=0).fit(data[:, :128])\n",
    "            label = kmeans.labels_\n",
    "            center = list(kmeans.cluster_centers_)\n",
    "            icenter.append(center)\n",
    "            for clus_idx in range(b):\n",
    "                data_in_clus = [m for m, n in enumerate(label) if n == clus_idx]\n",
    "                hi_kmeans(data[data_in_clus], b, depth - 1, icenter, ileaf, center)\n",
    "    else:\n",
    "        ileaf.append(data)\n",
    "\n",
    "    return icenter, ileaf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) Build the vocabulary tree with b=4, depth=3 and save the results to Hie_Tree_b4d3.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = 4\n",
    "depth = 3\n",
    "icenter, ileaf = hi_kmeans(database, b, depth, [], [], [])\n",
    "\n",
    "file = open('Hie_Tree_b4d3.txt', 'wb')\n",
    "pickle.dump((icenter, ileaf), file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) Build the vocabulary tree with b=4, depth=5 and save the results to Hie_Tree_b4d5.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = 4\n",
    "depth = 5\n",
    "icenter, ileaf = hi_kmeans(database, b, depth, [], [], [])\n",
    "\n",
    "file = open('Hie_Tree_b4d5.txt', 'wb')\n",
    "pickle.dump((icenter, ileaf), file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (c) Build the vocabulary tree with b=5, depth=7 and save the results to Hie_Tree_b5d7.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = 5\n",
    "depth = 7\n",
    "icenter, ileaf = hi_kmeans(database, b, depth, [], [], [])\n",
    "\n",
    "file = open('Hie_Tree_b5d7.txt', 'wb')\n",
    "pickle.dump((icenter, ileaf), file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Querying\n",
    "#### Test the three kinds of vocabulary tree with query image and record the top-1 and top-5 recall rates over 50 objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the required function for query and the computation of tf-idf/q vector/d vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def query(b, depth, icenter, data, index, out, positionx):\n",
    "    '''\n",
    "    :param b: The branch number of vocabulary tree\n",
    "    :param depth: The number of levels of the vocabulary tree\n",
    "    :param icenter: The center of all clusters that is divided in every level\n",
    "    :param data: The SIFT features from the query image\n",
    "    :param index: The relative position of the descriptor in the tree in current level\n",
    "    :param out: The label of the cluster a.k.a. visual words the descriptor finally belongs to\n",
    "    :param positionx: The relative position of the descriptor in the tree in all upper levels\n",
    "    :return: out\n",
    "    '''\n",
    "    if depth > 1:\n",
    "        minimum = np.linalg.norm(data - icenter[index][0])\n",
    "        position = 0\n",
    "        for x in range(1, b):\n",
    "            dist = np.linalg.norm(data - icenter[index][x])\n",
    "            if dist < minimum:\n",
    "                minimum = dist\n",
    "                position = x\n",
    "        index = int(index + 1 + position * ((np.power(b, depth-1) - 1)/(b-1)))\n",
    "        positionx.append(position)\n",
    "        query(b, depth-1, icenter, data, index, out, positionx)\n",
    "    else:\n",
    "        minimum = np.linalg.norm(data - icenter[index][0])\n",
    "        position = 0\n",
    "        for x in range(1, b):\n",
    "            dist = np.linalg.norm(data - icenter[index][x])\n",
    "            if dist < minimum:\n",
    "                minimum = dist\n",
    "                position = x\n",
    "        positionx.append(position)\n",
    "        loc = positionx[0] + 1\n",
    "        for i in positionx[1:len(positionx)]:\n",
    "            loc = loc * b - (b - (i + 1))\n",
    "        out.append(loc-1)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def Compute_idf_d(words, n_o_w):\n",
    "    '''\n",
    "    :param words: All visual words contained in the database\n",
    "    :param n_o_w: The number of all visual words in the database\n",
    "    :return: idf, d\n",
    "    '''\n",
    "    # Calculate idf values of each Visual Word and d vector for the server database\n",
    "    tf = np.zeros((n_o_w, 50))\n",
    "    idf = np.zeros(n_o_w)\n",
    "    d = np.zeros((n_o_w, 50))\n",
    "\n",
    "    # idf values only depends on the database and the structure of the vocabulary tree\n",
    "    for i in range(n_o_w):\n",
    "        idf[i] = np.log2(50 / len(set(list(words[i][:, -1]))))\n",
    "        for ob in words[i][:, -1]:\n",
    "            ob = int(ob - 1)\n",
    "            tf[i, ob] = tf[i, ob] + 1\n",
    "\n",
    "    # Compute d vector (tf-idf weight) of each object and save it to d matrix as a column\n",
    "    for j in range(50):\n",
    "        tf[:, j] = tf[:, j] / np.sum(tf[:, j])\n",
    "        d[:, j] = tf[:, j] * idf\n",
    "\n",
    "    return idf, d\n",
    "\n",
    "\n",
    "def Compute_q(word_q, n_o_w, idf):\n",
    "    '''\n",
    "    :param word_q: All visual words contained in a query image\n",
    "    :param n_o_w: The number of all visual words in the database\n",
    "    :param idf: The idf values given the database\n",
    "    :return: q vector of the query image\n",
    "    '''\n",
    "    # Calculate q vector for each query image document\n",
    "    tf = np.zeros(n_o_w)\n",
    "    q = np.zeros(n_o_w)\n",
    "\n",
    "    for i in range(len(word_q)):\n",
    "        tf[word_q[i]] += 1\n",
    "    tf /= np.sum(tf)\n",
    "\n",
    "    for j in range(n_o_w):\n",
    "        q[j] = tf[j] * idf[j]\n",
    "    q.reshape(-1, 1)\n",
    "\n",
    "    return q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the structure and node information of three trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "icenter_3 = [None] * 3\n",
    "ileaf_3 = [None] * 3\n",
    "with open('Hie_Tree_b4d3.txt', 'rb') as file:\n",
    "    icenter_3[0], ileaf_3[0] = pickle.load(file)\n",
    "with open('Hie_Tree_b4d5.txt', 'rb') as file:\n",
    "    icenter_3[1], ileaf_3[1] = pickle.load(file)\n",
    "with open('Hie_Tree_b5d7.txt', 'rb') as file:\n",
    "    icenter_3[2], ileaf_3[2] = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test the three kinds of vocabulary tree with query image and record the top-1 and top-5 recall rates over 50 objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rec_rate1 = np.zeros(3)\n",
    "rec_rate5 = np.zeros(3)\n",
    "b_all = [4, 4, 5]\n",
    "depth_all = [3, 5, 7]\n",
    "n_o_w_all = [np.power(4, 3), np.power(4, 5), np.power(5, 7)]\n",
    "\n",
    "for i_tree in range(3):\n",
    "    # Load the correct type of tree\n",
    "    icenter = icenter_3[i_tree]\n",
    "    ileaf = ileaf_3[i_tree]\n",
    "    n_o_w = n_o_w_all[i_tree]\n",
    "    b = b_all[i_tree]\n",
    "    depth = depth_all[i_tree]\n",
    "\n",
    "    # Initialization\n",
    "    rec1 = np.zeros(50)\n",
    "    rec5 = np.zeros(50)\n",
    "\n",
    "    # Compute the idf and d vector of the database\n",
    "    words = ileaf\n",
    "    idf, d = Compute_idf_d(words, n_o_w)\n",
    "\n",
    "    # Testing each query image\n",
    "    for j in range(50):\n",
    "        #Load descriptors in each image for query\n",
    "        des_q = pickle.load(open('./Query_des/des_client{}.pkl'.format(j+1), 'rb'))\n",
    "\n",
    "        # Query the vocabulary tree to find the word cluster the descriptor belonging to\n",
    "        word_q = []\n",
    "        for feature in des_q:\n",
    "            word = query(b, depth, icenter, feature, 0, [], [])\n",
    "            word_q.append(word)\n",
    "\n",
    "        # Compute the q vector for each query image\n",
    "        q = Compute_q(word_q, n_o_w, idf)\n",
    "\n",
    "        # Calculate the qd score between all possible match and select the smallest one as best match\n",
    "        score = np.zeros(50)\n",
    "        for k in range(50):\n",
    "            d_doc = d[:, k]\n",
    "            score[k] = np.linalg.norm((d_doc/np.linalg.norm(d_doc, ord=1) - q/np.linalg.norm(q, ord=1)), ord=1)\n",
    "        top = np.argsort(score)\n",
    "\n",
    "        # Count the number of correct matches when only top1 is the correct object\n",
    "        if top[0] == j:\n",
    "            rec1[j] = rec1[j] + 1\n",
    "\n",
    "        # Count the number of correct matches as long as one in top5 is the correct object\n",
    "        for m in range(5):\n",
    "            if top[m] == j:\n",
    "                rec5[j] = rec5[j] + 1\n",
    "\n",
    "    # TOP 1 Accuracy\n",
    "    rec_rate1[i_tree] = np.mean(rec1)\n",
    "    # TOP 5 Accuracy\n",
    "    rec_rate5[i_tree] = np.mean(rec5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top1 recall rates when vocabulary tree with settings b4d3, b4d5 and b5d7 is:\n",
      "[0.1  0.74 0.84]\n",
      "The top5 recall rates when vocabulary tree with settings b4d3, b4d5 and b5d7 is:\n",
      "[0.36 0.8  0.9 ]\n"
     ]
    }
   ],
   "source": [
    "print('The top1 recall rates when vocabulary tree with settings b4d3, b4d5 and b5d7 is:')\n",
    "print(rec_rate1)\n",
    "print('The top5 recall rates when vocabulary tree with settings b4d3, b4d5 and b5d7 is:')\n",
    "print(rec_rate5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test the b=5, depth=7 vocabulary tree with 50, 70 or 90 percent of query features and record the top-1 and top-5 recall rates over 50 objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the information of correct type of tree\n",
    "with open('Hie_Tree_b5d7.txt', 'rb') as file:\n",
    "    icenter, ileaf = pickle.load(file)\n",
    "\n",
    "# Define query factors\n",
    "query_factor = [0.5, 0.7, 0.9]\n",
    "\n",
    "# Compute the idf and d vector of the database\n",
    "b = 5\n",
    "depth = 7\n",
    "words = ileaf\n",
    "n_o_w = np.power(b, depth)  # number of visual words\n",
    "idf, d = Compute_idf_d(words, n_o_w)\n",
    "\n",
    "# Querying\n",
    "rec_b5d7_top1 = np.zeros(len(query_factor))\n",
    "rec_b5d7_top5 = np.zeros(len(query_factor))\n",
    "\n",
    "for r in range(len(query_factor)):\n",
    "    q_factor = query_factor[r]\n",
    "\n",
    "    # Initialization\n",
    "    rec1 = np.zeros(50)\n",
    "    rec5 = np.zeros(50)\n",
    "\n",
    "    # Randomly select query_factor amount of descriptors in each image for query\n",
    "    for j in range(50):\n",
    "        des_q = pickle.load(open('./Query_des/des_client{}.pkl'.format(j+1), 'rb'))\n",
    "        ran_idx = np.random.randint(des_q.shape[0], size=round(q_factor*des_q.shape[0]))\n",
    "        des_q = des_q[ran_idx]\n",
    "\n",
    "        # Query the vocabulary tree to find the word cluster the descriptor belonging to\n",
    "        word_q = []\n",
    "        for feature in des_q:\n",
    "            word = query(b, depth, icenter, feature, 0, [], [])\n",
    "            word_q.append(word)\n",
    "\n",
    "        # Compute the q vector for each query image\n",
    "        q = Compute_q(word_q, n_o_w, idf)\n",
    "\n",
    "        # Calculate the qd score between all possible match and select the smallest one as best match\n",
    "        score = np.zeros(50)\n",
    "        for k in range(50):\n",
    "            d_doc = d[:, k]\n",
    "            score[k] = np.linalg.norm((d_doc/np.linalg.norm(d_doc, ord=1) - q/np.linalg.norm(q, ord=1)), ord=1)\n",
    "        top = np.argsort(score)\n",
    "\n",
    "        # Count the number of correct matches when only top1 is the correct object\n",
    "        if top[0] == j:\n",
    "            rec1[j] = rec1[j] + 1\n",
    "\n",
    "        # Count the number of correct matches as long as one in top5 is the correct object\n",
    "        for m in range(5):\n",
    "            if top[m] == j:\n",
    "                rec5[j] = rec5[j] + 1\n",
    "\n",
    "    # TOP 1 Accuracy\n",
    "    rec_b5d7_top1[r] = np.mean(rec1)\n",
    "    # TOP 5 Accuracy\n",
    "    rec_b5d7_top5[r] = np.mean(rec5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top1 recall rates when query rate is 0.5, 0.7, 0.9 for vocabulary tree with settings b5d7 is:\n",
      "[0.8  0.84 0.84]\n",
      "The top5 recall rates when query rate is 0.5, 0.7, 0.9 for vocabulary tree with settings b5d7 is:\n",
      "[0.9  0.94 0.92]\n"
     ]
    }
   ],
   "source": [
    "print('The top1 recall rates when query rate is 0.5, 0.7, 0.9 for vocabulary tree with settings b5d7 is:')\n",
    "print(rec_b5d7_top1)\n",
    "print('The top5 recall rates when query rate is 0.5, 0.7, 0.9 for vocabulary tree with settings b5d7 is:')\n",
    "print(rec_b5d7_top5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
