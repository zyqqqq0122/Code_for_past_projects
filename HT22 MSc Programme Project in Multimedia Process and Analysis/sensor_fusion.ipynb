{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "from scipy.stats import wasserstein_distance\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    with np.load(path) as data:\n",
    "        pi = data[\"pi\"]\n",
    "        A = data[\"A\"]\n",
    "        B = data[\"B\"]\n",
    "        param = data[\"param\"]\n",
    "        bins_z = data[\"bins_z\"]\n",
    "        bins_co2 = data[\"bins_co2\"]\n",
    "        \n",
    "    return pi, A, B, param, bins_z, bins_co2\n",
    "\n",
    "\n",
    "def forward(x,pi,A,b):\n",
    "    \"\"\"\n",
    "    To calculate scaled forward variables \n",
    "    Returns: alphaHat = P(S_t=i|x) probability of a state i at time instance t given observations x\n",
    "    x: observations (T, )\n",
    "    pi: initial state probability (N, )\n",
    "    A: Transition probability matrix (N,N)\n",
    "    b: emission probability matrix (N, len(np.unique(observations)))\n",
    "    \"\"\"\n",
    "    N = np.shape(b)[0]\n",
    "    T = np.shape(x)[0]\n",
    "    alphaTemp = np.zeros((N,T))\n",
    "    alphaHat = np.zeros((N,T))\n",
    "    c = np.zeros(T)\n",
    "\n",
    "    #Initialization\n",
    "    alphaTemp[:,0] = pi*b[:,x[0]]\n",
    "    c[0] = np.sum(alphaTemp[:,0])\n",
    "    alphaHat[:,0]=alphaTemp[:,0]/c[0]\n",
    "    #print(alphaTemp[:,0])\n",
    "    #Forward step\n",
    "    for t in range (1,T):\n",
    "            for j in range(N):\n",
    "                alphaTemp[j,t] = b[j,x[t]]*(np.dot(alphaHat[:,t-1],A[:,j]))\n",
    "                #print(\"alphaTemp[j,t]:\",b[j,x[t]],(np.dot(alphaHat[:,t-1],A[:,j])))\n",
    "            c[t] = np.sum(alphaTemp[:,t])\n",
    "            #print(\"c[t]:\",c[t])\n",
    "            alphaHat[:,t]=alphaTemp[:,t]/c[t]\n",
    "            #print(\"alphaHat[:,t]\", alphaHat[:,t])\n",
    "            \n",
    "    return(alphaHat,c)\n",
    "\n",
    "\n",
    "def sync_sequence(timestamps,data):\n",
    "    start_indices = []\n",
    "    for ind,t in enumerate(timestamps):\n",
    "        df = data[ind]\n",
    "        df['create_time'] = pd.date_range('01/01/2022 00:00:00', periods=len(df), freq='1T')\n",
    "        df.loc[:, 'create_time'] = pd.to_datetime(df.loc[:, 'create_time'])\n",
    "        df = df.set_index('create_time')\n",
    "        data_time = np.array(df.time.resample('20T').min())\n",
    "\n",
    "        \"\"\"data_time = np.array(data[ind].time)\"\"\"\n",
    "\n",
    "        start = np.where(data_time==t)[0][0]\n",
    "        start_indices.append(start)\n",
    "\n",
    "    return start_indices\n",
    "\n",
    "\n",
    "def get_measurement_sequence(start_ind,amt,data):\n",
    "    \n",
    "    #data = data.drop(data.index[detect_outliers(data.lp8_T)])\n",
    "    #data = data.drop(data.index[detect_outliers(data.lp8_ir)])\n",
    "    #data = data.drop(data.index[detect_outliers(data.lp8_CO2)])\n",
    "\n",
    "    #data = data.dropna()\n",
    "    #data = data.drop(data.index[np.unique(np.hstack((detect_outliers(data.lp8_CO2), detect_outliers(data.S_co2), detect_outliers(data.lp8_T), detect_outliers(data.lp8_ir))))])\n",
    "\n",
    "    data['create_time'] = pd.date_range('01/01/2022 00:00:00', periods=len(data), freq='1T')\n",
    "    data.loc[:, 'create_time'] = pd.to_datetime(data.loc[:, 'create_time'])\n",
    "    data = data.set_index('create_time')\n",
    "    data_time = np.array(data.time.resample('20T').min())[start_ind:start_ind+amt]\n",
    "    ref_meas = np.array(data.S_co2.resample('20T').mean())[start_ind:start_ind+amt]\n",
    "    #ref_temp = np.array(data[5].resample('16T').mean())\n",
    "    data_CO2 = np.array(data.lp8_CO2.resample('20T').mean())[start_ind:start_ind+amt]\n",
    "    data_temp = np.array(data.lp8_T.resample('20T').mean())[start_ind:start_ind+amt]\n",
    "    data_ir = np.array(data.lp8_ir.resample('20T').mean())[start_ind:start_ind+amt]\n",
    "\n",
    "    \"\"\"\n",
    "    data_time = np.array(data.time)[start_ind:start_ind+amt*20:20]\n",
    "    data_temp = np.array(data.lp8_T)[start_ind:start_ind+amt*20:20]\n",
    "    data_ir = np.array(data.lp8_ir)[start_ind:start_ind+amt*20:20]\n",
    "    data_CO2 = np.array(data.lp8_CO2)[start_ind:start_ind+amt*20:20]\n",
    "    ref_meas = np.array(data.S_co2)[start_ind:start_ind+amt*20:20]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(data_time[0],data_time[-1])\n",
    "\n",
    "    return data_temp,data_ir,data_CO2,ref_meas,data_time\n",
    "\n",
    "\n",
    "def state_to_value(states,bins):\n",
    "    zeros = np.zeros_like(states)\n",
    "    itvl = bins[-1] - bins[-2]\n",
    "    for i in range(len(states)):\n",
    "        if i == 0:\n",
    "            zeros[states == i] = bins[i] - itvl / 2     \n",
    "        elif i == len(bins):\n",
    "            zeros[states == i] = bins[-1] + itvl / 2\n",
    "        else:\n",
    "            zeros[states == i] = (bins[i] + bins[i - 1]) / 2\n",
    "\n",
    "    return zeros\n",
    "\n",
    "\n",
    "def calc_co2(zero, ir, temp, s, t0, tz, tz2, ts, ts2,fp):\n",
    "\n",
    "    \"\"\"\n",
    "    Mapping sensor measurements to concentration level of CO2 based on Beer-Lambert Law\n",
    "    :param zero: zero calibration parameter\n",
    "    :param ir: amount of IR light received by detector\n",
    "    :param temp: measured environmental temperature\n",
    "    :param s: span calibration parameter\n",
    "    :param t0: full transmittance (scaled and shifted transmittance when the target concentration is zero)\n",
    "    :param tz: temperature calibration parameter, describes the temperature dependency of zero\n",
    "    :param tz2: temperature calibration parameter, describes the temperature dependency of zero\n",
    "    :param ts: temperature calibration parameter, describes the temperature dependency of span\n",
    "    :param ts2: temperature calibration parameter, describes the temperature dependency of span\n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    The formula is owned by the company.\n",
    "    '''\n",
    "\n",
    "    return co2\n",
    "\n",
    "\n",
    "def viterbi_log(y, pi, A, B):\n",
    "\n",
    "    \"\"\"\n",
    "    Viterbi Algorithm\n",
    "    :param y: observations (N, )\n",
    "    :param pi: state probability (S, )\n",
    "    :param A: transition probability matrix (S, S)\n",
    "    :param B: observation probability matrix (S, N)\n",
    "    :return: predicted state sequence (N, )\n",
    "    \"\"\"\n",
    "\n",
    "    S = A.shape[0]    # Number of states\n",
    "    N = len(y)  # Length of observation sequence\n",
    "    tiny = np.finfo(0.).tiny\n",
    "    pi_log = np.log(pi + tiny)\n",
    "    A_log = np.log(A + tiny)\n",
    "    B_log = np.log(B + tiny)\n",
    "\n",
    "    # Initialization\n",
    "    ### Viterbi probability vector\n",
    "    D_log = np.zeros((S, N))\n",
    "    D_log[:, 0] = pi_log + B_log[:, y[0]]\n",
    "    ### Viterbi backpointer matrix\n",
    "    E = np.zeros((S, N - 1)).astype(np.int32)\n",
    "\n",
    "    # Viterbi forward step\n",
    "    for n in range(1, N):\n",
    "        for i in range(S):\n",
    "            temp_sum = A_log[:, i] + D_log[:, n - 1]\n",
    "            D_log[i, n] = np.max(temp_sum) + B_log[i, y[n]]\n",
    "            E[i, n - 1] = np.argmax(temp_sum)\n",
    "\n",
    "    # Backtracking\n",
    "    S_opt = np.zeros(N).astype(np.int32)\n",
    "    S_opt[-1] = np.argmax(D_log[:, -1])\n",
    "    for n in range(N - 2, -1, -1):\n",
    "        S_opt[n] = E[int(S_opt[n + 1]), n]\n",
    "\n",
    "    return S_opt\n",
    "\n",
    "\n",
    "def sensor_fusion_dsrule(p):\n",
    "    fused_belief = np.prod(p,axis=1)\n",
    "    if np.sum(fused_belief) != 0:\n",
    "        fused_belief = fused_belief/np.sum(fused_belief)\n",
    "    return fused_belief\n",
    "\n",
    "\n",
    "def sensor_fusion_wavg(p):\n",
    "    #Wasserstein distance\n",
    "    I = p.shape[1]\n",
    "    dist = np.zeros((I,I))\n",
    "    for i in range(I):\n",
    "        for j in range(I):\n",
    "            dist[i,j] = wasserstein_distance(p[:,i],p[:,j])\n",
    "    #Normalize distances\n",
    "    n_dist = 2*dist/np.sum(dist)\n",
    "\n",
    "    #Similarity between belief functions\n",
    "    s = 1-n_dist\n",
    "\n",
    "    #Support degrees, i-th element is support degree of belief function P_i\n",
    "    supp_deg = np.sum(s,axis = 0)\n",
    "    #Weighting factors\n",
    "    weights = supp_deg/np.sum(supp_deg)\n",
    "\n",
    "    #Weighted average of I belief functions\n",
    "    P_hat = np.sum(weights*p, axis = 1)\n",
    "\n",
    "    #DS rule to combine P_hat\n",
    "    fused_belief = np.zeros_like(P_hat)\n",
    "    norm_factor = 0\n",
    "    for k in range(P_hat.shape[0]):\n",
    "        fused_belief[k] = P_hat[k]**(I)\n",
    "        norm_factor += P_hat[k]**(I)\n",
    "    fused_belief = fused_belief/norm_factor\n",
    "\n",
    "    return fused_belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "pi_0, A_0, B_0, param_0, bins_z_0, bins_co2_0 = load_model(\"sensor_fusion/1214_5_days_diff/1214_LP8_Supervised_HMM_Sensor_00.npz\")\n",
    "pi_1, A_1, B_1, param_1, bins_z_1, bins_co2_1 = load_model(\"sensor_fusion/1214_5_days_diff/1214_LP8_Supervised_HMM_Sensor_01.npz\")\n",
    "pi_2, A_2, B_2, param_2, bins_z_2, bins_co2_2 = load_model(\"sensor_fusion/1214_5_days_diff/1214_LP8_Supervised_HMM_Sensor_02.npz\")\n",
    "pi_3, A_3, B_3, param_3, bins_z_3, bins_co2_3 = load_model(\"sensor_fusion/1214_5_days_diff/1214_LP8_Supervised_HMM_Sensor_03.npz\")\n",
    "pi_4, A_4, B_4, param_4, bins_z_4, bins_co2_4 = load_model(\"sensor_fusion/1214_5_days_diff/1214_LP8_Supervised_HMM_Sensor_04.npz\")\n",
    "\n",
    "#No. of states for each HMM\n",
    "N_0 = pi_0.shape[0]\n",
    "N_1 = pi_1.shape[0]\n",
    "N_2 = pi_2.shape[0]\n",
    "N_3 = pi_3.shape[0]\n",
    "N_4 = pi_4.shape[0]\n",
    "\n",
    "#Map each state with a corresponding zero value\n",
    "zeros_0 = state_to_value(np.arange(N_0),bins_z_0)\n",
    "zeros_1 = state_to_value(np.arange(N_1),bins_z_1)\n",
    "zeros_2 = state_to_value(np.arange(N_2),bins_z_2)\n",
    "zeros_3 = state_to_value(np.arange(N_3),bins_z_3)\n",
    "zeros_4 = state_to_value(np.arange(N_4),bins_z_4)\n",
    "\n",
    "data0 = pd.read_csv(\"data/Measurements/5_days_diff/kth_logger_00.csv\", delimiter=',')\n",
    "data1 = pd.read_csv(\"data/Measurements/5_days_diff/kth_logger_01.csv\", delimiter=',')\n",
    "data2 = pd.read_csv(\"data/Measurements/5_days_diff/kth_logger_02.csv\", delimiter=',')\n",
    "data3 = pd.read_csv(\"data/Measurements/5_days_diff/kth_logger_03.csv\", delimiter=',')\n",
    "data4 = pd.read_csv(\"data/Measurements/5_days_diff/kth_logger_04.csv\", delimiter=',')\n",
    "\n",
    "start_timestamps = [\"2022-12-05 21:04:59\",\"2022-12-05 20:56:41\",\"2022-12-05 21:02:28\",\"2022-12-05 21:03:46\",\"2022-12-05 21:07:18\"]\n",
    "data = [data0, data1, data2, data3, data4]\n",
    "start_i = sync_sequence(start_timestamps,data)\n",
    "\n",
    "L = 95\n",
    "\n",
    "fused_co2 = np.zeros(L)\n",
    "refs = np.zeros((L))\n",
    "pre_co2s = np.zeros((L,5))\n",
    "\n",
    "#Observe the L measurements\n",
    "data_temp_0,data_ir_0,data_CO2_0,ref0,data_time_0 = get_measurement_sequence(start_i[0],L,data0)\n",
    "data_temp_1,data_ir_1,data_CO2_1,ref1,data_time_1 = get_measurement_sequence(start_i[1],L,data1)\n",
    "data_temp_2,data_ir_2,data_CO2_2,ref2,_ = get_measurement_sequence(start_i[2],L,data2)\n",
    "data_temp_3,data_ir_3,data_CO2_3,ref3,_ = get_measurement_sequence(start_i[3],L,data3)\n",
    "data_temp_4,data_ir_4,data_CO2_4,ref4,_ =  get_measurement_sequence(start_i[4],L,data4)\n",
    "\n",
    "\n",
    "all_refs = np.stack((ref0,ref1,ref2,ref3,ref4),axis = 1)\n",
    "\n",
    "x0 = np.digitize(data_CO2_0,bins_co2_0)\n",
    "x1 = np.digitize(data_CO2_1,bins_co2_1)\n",
    "x2 = np.digitize(data_CO2_2,bins_co2_2)\n",
    "x3 = np.digitize(data_CO2_3,bins_co2_3)\n",
    "x4 = np.digitize(data_CO2_4,bins_co2_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Forward Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate belief functions\n",
    "A_0 = (A_0 + 1e-10)/np.sum(A_0 + 1e-10,axis=1)\n",
    "beliefs_0,_ = forward(x0,pi_0,A_0,B_0)\n",
    "A_1 = (A_1 + 1e-10)/np.sum(A_1 + 1e-10,axis=1)\n",
    "beliefs_1,_ = forward(x1,pi_1,A_1,B_1)\n",
    "A_2 = (A_2 + 1e-10)/np.sum(A_2 + 1e-10,axis=1)\n",
    "beliefs_2,_ = forward(x2,pi_2,A_2,B_2)\n",
    "A_3 = (A_3 + 1e-10)/np.sum(A_3 + 1e-10,axis=1)\n",
    "beliefs_3,_ = forward(x3,pi_3,A_3,B_3)\n",
    "A_4 = (A_4 + 1e-10)/np.sum(A_4 + 1e-10,axis=1)\n",
    "beliefs_4,_ = forward(x4,pi_4,A_4,B_4)\n",
    "\n",
    "#For plotting purposes, predicted co2 for each sensor\n",
    "pre_state_0 = viterbi_log(x0,pi_0,A_0,B_0)\n",
    "pre_state_1 = viterbi_log(x1,pi_1,A_1,B_1)\n",
    "pre_state_2 = viterbi_log(x2,pi_2,A_2,B_2)\n",
    "pre_state_3 = viterbi_log(x3,pi_3,A_3,B_3)\n",
    "pre_state_4 = viterbi_log(x4,pi_4,A_4,B_4)\n",
    "\n",
    "for i in range(L):\n",
    "    #Map distribution of zeros into co2 \n",
    "    co2_values_0 = calc_co2(zeros_0,data_ir_0[i]*2**(-8),data_temp_0[i],param_0[5],61440,param_0[0],param_0[1],param_0[2],param_0[3],param_0[6:])\n",
    "    co2_values_1 = calc_co2(zeros_1,data_ir_1[i]*2**(-8),data_temp_1[i],param_1[5],61440,param_1[0],param_1[1],param_1[2],param_1[3],param_1[6:])\n",
    "    co2_values_2 = calc_co2(zeros_2,data_ir_2[i]*2**(-8),data_temp_2[i],param_2[5],61440,param_2[0],param_2[1],param_2[2],param_2[3],param_2[6:])\n",
    "    co2_values_3 = calc_co2(zeros_3,data_ir_3[i]*2**(-8),data_temp_3[i],param_3[5],61440,param_3[0],param_3[1],param_3[2],param_3[3],param_3[6:])\n",
    "    co2_values_4 = calc_co2(zeros_4,data_ir_4[i]*2**(-8),data_temp_4[i],param_4[5],61440,param_4[0],param_4[1],param_4[2],param_4[3],param_4[6:])\n",
    "    \n",
    "    if i == 25:\n",
    "        #Plot belief functions\n",
    "        fig, axs = plt.subplots(nrows=5, ncols=1, sharex=True,sharey=True)\n",
    "        axs[0].plot(co2_values_0,beliefs_0[:,i])\n",
    "        axs[1].plot(co2_values_1,beliefs_1[:,i])\n",
    "        axs[2].plot(co2_values_2,beliefs_2[:,i])\n",
    "        axs[3].plot(co2_values_3,beliefs_3[:,i])\n",
    "        axs[4].plot(co2_values_4,beliefs_4[:,i])\n",
    "        fig.suptitle(\"Belief Functions\")\n",
    "        fig.supylabel('Probability')\n",
    "        fig.supxlabel('CO2 Level in ppm')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    #Interpolation\n",
    "    all_co2 = np.concatenate((co2_values_0,co2_values_1,co2_values_2,co2_values_3,co2_values_4))\n",
    "    all_co2 = np.sort(all_co2)\n",
    "\n",
    "    belief_0_inter=np.zeros(all_co2.shape)\n",
    "    belief_0_inter[np.searchsorted(all_co2,co2_values_0)]=beliefs_0[:,i]\n",
    "    belief_1_inter = np.zeros(all_co2.shape)\n",
    "    belief_1_inter[np.searchsorted(all_co2,co2_values_1)]=beliefs_1[:,i]\n",
    "    belief_2_inter = np.zeros(all_co2.shape)\n",
    "    belief_2_inter[np.searchsorted(all_co2,co2_values_2)]=beliefs_2[:,i]\n",
    "    belief_3_inter = np.zeros(all_co2.shape)\n",
    "    belief_3_inter[np.searchsorted(all_co2,co2_values_3)]=beliefs_3[:,i]\n",
    "    belief_4_inter = np.zeros(all_co2.shape)\n",
    "    belief_4_inter[np.searchsorted(all_co2,co2_values_4)]=beliefs_4[:,i]\n",
    "    \n",
    "    \n",
    "    if i == 25:\n",
    "        fig, axs = plt.subplots(nrows=5, ncols=1, sharex=True,sharey=True)\n",
    "        axs[0].plot(all_co2,belief_0_inter)\n",
    "        axs[1].plot(all_co2,belief_1_inter)\n",
    "        axs[2].plot(all_co2,belief_2_inter)\n",
    "        axs[3].plot(all_co2,belief_3_inter)\n",
    "        axs[4].plot(all_co2,belief_4_inter)\n",
    "        fig.suptitle(\"Belief Functions, interpolated\")\n",
    "        fig.supylabel('Probability')\n",
    "        fig.supxlabel('CO2 Level in ppm')\n",
    "        plt.show()\n",
    "    \n",
    "    #Stack all belief functions into one\n",
    "    beliefs = np.stack((belief_0_inter,belief_1_inter,belief_2_inter,belief_3_inter,belief_4_inter),axis=1)\n",
    "\n",
    "    #Belief fusion\n",
    "    fused_DS = sensor_fusion_dsrule(beliefs)\n",
    "    fused_wavg = sensor_fusion_wavg(beliefs)\n",
    "\n",
    "    \n",
    "    if i == 25:\n",
    "        plt.plot(all_co2,fused_wavg)\n",
    "        plt.title(\"Weighted average approach\")\n",
    "        plt.xlabel('CO2 Level in ppm')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    fused_co2[i]=all_co2[np.argmax(fused_wavg)]\n",
    "    \n",
    "    #Plotting purposes\n",
    "    pre_co2_0 = calc_co2(zeros_0[pre_state_0[i]],data_ir_0[i]*2**(-8),data_temp_0[i],param_0[5],61440,param_0[0],param_0[1],param_0[2],param_0[3],param_0[6:])\n",
    "    pre_co2_1 = calc_co2(zeros_1[pre_state_1[i]],data_ir_1[i]*2**(-8),data_temp_1[i],param_1[5],61440,param_1[0],param_1[1],param_1[2],param_1[3],param_1[6:])\n",
    "    pre_co2_2 = calc_co2(zeros_2[pre_state_2[i]],data_ir_2[i]*2**(-8),data_temp_2[i],param_2[5],61440,param_2[0],param_2[1],param_2[2],param_2[3],param_2[6:])\n",
    "    pre_co2_3 = calc_co2(zeros_3[pre_state_3[i]],data_ir_3[i]*2**(-8),data_temp_3[i],param_3[5],61440,param_3[0],param_3[1],param_3[2],param_3[3],param_3[6:])\n",
    "    pre_co2_4 = calc_co2(zeros_4[pre_state_4[i]],data_ir_4[i]*2**(-8),data_temp_4[i],param_4[5],61440,param_4[0],param_4[1],param_4[2],param_4[3],param_4[6:])\n",
    "    pre_co2s[i,0] = pre_co2_0\n",
    "    pre_co2s[i,1] = pre_co2_1\n",
    "    pre_co2s[i,2] = pre_co2_2\n",
    "    pre_co2s[i,3] = pre_co2_3\n",
    "    pre_co2s[i,4] = pre_co2_4\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(fused_co2.shape[0]),fused_co2,np.mean(all_refs,axis = 1))\n",
    "#plt.plot(np.arange(fused_co2.shape[0]),pre_co2s)\n",
    "plt.ylabel(\"Co2 concentration in ppm\")\n",
    "plt.title(\"Sensor fusion results, belief functions with forward algorithm\")\n",
    "plt.legend(labels=[\"Fused result\",\"Mean of references\", \"Predicted co2 0\", \"Predicted co2 1\",\"Predicted co2 2\",\"Predicted co2 3\",\"Predicted co2 4\"])\n",
    "#data_time = np.array(data0.time)[start_i[0]:L*20+start_i[0]]\n",
    "plt.xticks(np.array([0,L-1]), [data_time_0[0], data_time_0[-1]])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(fused_co2.shape[0]),ref0, color='tab:red')\n",
    "plt.plot(np.arange(fused_co2.shape[0]),ref1, color ='tab:brown')\n",
    "plt.plot(np.arange(fused_co2.shape[0]),ref3, color = 'tab:purple')\n",
    "#plt.plot(np.arange(fused_co2.shape[0]),fused_co2, color = 'tab:blue')\n",
    "plt.legend(labels = [\"ref0\",\"ref1\",\"ref3\"])\n",
    "plt.title(\"Reference measurements\")\n",
    "plt.ylabel(\"Co2 concentration in ppm\")\n",
    "plt.xticks(np.array([0,L-1]), [data_time_0[0], data_time_0[-1]])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(fused_co2.shape[0]),fused_co2)\n",
    "plt.plot(np.arange(fused_co2.shape[0]),np.mean(all_refs,axis = 1),np.mean(pre_co2s,axis = 1))\n",
    "plt.xticks(np.array([0,L-1]), [data_time_0[0], data_time_0[-1]])\n",
    "plt.title(\"Sensor fusion results, belief functions with forward algorithm\")\n",
    "plt.legend(labels = [\"Sensor fusion results\", \"Mean of references\",\"Mean of predictions\"])\n",
    "plt.ylabel(\"Co2 concentration in ppm\")\n",
    "plt.xticks(np.array([0,L-1]), [data_time_0[0], data_time_0[-1]])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "print(end-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# predicted co2 for each sensor\n",
    "pre_state_0 = viterbi_log(x0,pi_0,A_0,B_0)\n",
    "pre_state_1 = viterbi_log(x1,pi_1,A_1,B_1)\n",
    "pre_state_2 = viterbi_log(x2,pi_2,A_2,B_2)\n",
    "pre_state_3 = viterbi_log(x3,pi_3,A_3,B_3)\n",
    "pre_state_4 = viterbi_log(x4,pi_4,A_4,B_4)\n",
    "\n",
    "beliefs_0 = A_0[pre_state_0,:].T[:,0:-1]\n",
    "beliefs_1 = A_1[pre_state_1,:].T[:,0:-1]\n",
    "beliefs_2 = A_2[pre_state_2,:].T[:,0:-1]\n",
    "beliefs_3 = A_3[pre_state_3,:].T[:,0:-1]\n",
    "beliefs_4 = A_4[pre_state_4,:].T[:,0:-1]\n",
    "\n",
    "for i in range(beliefs_0.shape[1]):\n",
    "    #Map distribution of zeros into co2 \n",
    "    co2_values_0 = calc_co2(zeros_0,data_ir_0[i+1]*2**(-8),data_temp_0[i+1],param_0[5],61440,param_0[0],param_0[1],param_0[2],param_0[3],param_0[6:])\n",
    "    co2_values_1 = calc_co2(zeros_1,data_ir_1[i+1]*2**(-8),data_temp_1[i+1],param_1[5],61440,param_1[0],param_1[1],param_1[2],param_1[3],param_1[6:])\n",
    "    co2_values_2 = calc_co2(zeros_2,data_ir_2[i+1]*2**(-8),data_temp_2[i+1],param_2[5],61440,param_2[0],param_2[1],param_2[2],param_2[3],param_2[6:])\n",
    "    co2_values_3 = calc_co2(zeros_3,data_ir_3[i+1]*2**(-8),data_temp_3[i+1],param_3[5],61440,param_3[0],param_3[1],param_3[2],param_3[3],param_3[6:])\n",
    "    co2_values_4 = calc_co2(zeros_4,data_ir_4[i+1]*2**(-8),data_temp_4[i+1],param_4[5],61440,param_4[0],param_4[1],param_4[2],param_4[3],param_4[6:])\n",
    "\n",
    "    if i == 25:\n",
    "        #Plot belief functions\n",
    "        fig, axs = plt.subplots(nrows=5, ncols=1, sharex=True,sharey=True)\n",
    "        axs[0].plot(co2_values_0,beliefs_0[:,i])\n",
    "        axs[1].plot(co2_values_1,beliefs_1[:,i])\n",
    "        axs[2].plot(co2_values_2,beliefs_2[:,i])\n",
    "        axs[3].plot(co2_values_3,beliefs_3[:,i])\n",
    "        axs[4].plot(co2_values_4,beliefs_4[:,i])\n",
    "        fig.suptitle(\"Belief Functions\")\n",
    "        fig.supylabel('Probability')\n",
    "        fig.supxlabel('CO2 Level in ppm')\n",
    "        plt.show()\n",
    "\n",
    "    #Interpolation\n",
    "    all_co2 = np.concatenate((co2_values_0,co2_values_1,co2_values_2,co2_values_3,co2_values_4))\n",
    "    #all_co2 = np.concatenate((co2_values_1,co2_values_2,co2_values_3,co2_values_4))\n",
    "    all_co2 = np.sort(all_co2)\n",
    "    \n",
    "    belief_0_inter=np.zeros(all_co2.shape)\n",
    "    belief_0_inter[np.searchsorted(all_co2,co2_values_0)]=beliefs_0[:,i]\n",
    "    belief_1_inter = np.zeros(all_co2.shape)\n",
    "    belief_1_inter[np.searchsorted(all_co2,co2_values_1)]=beliefs_1[:,i]\n",
    "    belief_2_inter = np.zeros(all_co2.shape)\n",
    "    belief_2_inter[np.searchsorted(all_co2,co2_values_2)]=beliefs_2[:,i]\n",
    "    belief_3_inter = np.zeros(all_co2.shape)\n",
    "    belief_3_inter[np.searchsorted(all_co2,co2_values_3)]=beliefs_3[:,i]\n",
    "    belief_4_inter = np.zeros(all_co2.shape)\n",
    "    belief_4_inter[np.searchsorted(all_co2,co2_values_4)]=beliefs_4[:,i]\n",
    "\n",
    "    if i == 25:\n",
    "        fig, axs = plt.subplots(nrows=5, ncols=1, sharex=True,sharey=True)\n",
    "        axs[0].plot(all_co2,belief_0_inter)\n",
    "        axs[1].plot(all_co2,belief_1_inter)\n",
    "        axs[2].plot(all_co2,belief_2_inter)\n",
    "        axs[3].plot(all_co2,belief_3_inter)\n",
    "        axs[4].plot(all_co2,belief_4_inter)\n",
    "        fig.suptitle(\"Belief Functions, interpolated\")\n",
    "        fig.supylabel('Probability')\n",
    "        fig.supxlabel('CO2 Level in ppm')\n",
    "        plt.show()\n",
    "\n",
    "    #Stack all belief functions into one\n",
    "    beliefs = np.stack((belief_0_inter,belief_1_inter,belief_2_inter,belief_3_inter,belief_4_inter),axis=1)\n",
    "\n",
    "    #Belief fusion\n",
    "    fused_DS = sensor_fusion_dsrule(beliefs)\n",
    "    fused_wavg = sensor_fusion_wavg(beliefs,i)\n",
    "\n",
    "    if i == 25:\n",
    "        fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True,sharey=True)\n",
    "        axs[0].plot(all_co2,fused_DS)\n",
    "        axs[0].set_title(\"Dempster's rule\")\n",
    "        axs[1].plot(all_co2,fused_wavg)\n",
    "        axs[1].set_title(\"Weighted average approach\")\n",
    "        fig.supylabel('Probability')\n",
    "        fig.supxlabel('CO2 Level in ppm')\n",
    "        plt.show()\n",
    "\n",
    "    fused_co2[i]=all_co2[np.argmax(fused_wavg)]\n",
    "\n",
    "    #For plotting predicitions\n",
    "    pre_co2_0 = calc_co2(zeros_0[pre_state_0[i+1]],data_ir_0[i+1]*2**(-8),data_temp_0[i+1],param_0[5],61440,param_0[0],param_0[1],param_0[2],param_0[3],param_0[6:])\n",
    "    pre_co2_1 = calc_co2(zeros_1[pre_state_1[i+1]],data_ir_1[i+1]*2**(-8),data_temp_1[i+1],param_1[5],61440,param_1[0],param_1[1],param_1[2],param_1[3],param_1[6:])\n",
    "    pre_co2_2 = calc_co2(zeros_2[pre_state_2[i+1]],data_ir_2[i+1]*2**(-8),data_temp_2[i+1],param_2[5],61440,param_2[0],param_2[1],param_2[2],param_2[3],param_2[6:])\n",
    "    pre_co2_3 = calc_co2(zeros_3[pre_state_3[i+1]],data_ir_3[i+1]*2**(-8),data_temp_3[i+1],param_3[5],61440,param_3[0],param_3[1],param_3[2],param_3[3],param_3[6:])\n",
    "    pre_co2_4 = calc_co2(zeros_4[pre_state_4[i+1]],data_ir_4[i+1]*2**(-8),data_temp_4[i+1],param_4[5],61440,param_4[0],param_4[1],param_4[2],param_4[3],param_4[6:])\n",
    "    pre_co2s[i,0] = pre_co2_0\n",
    "    pre_co2s[i,1] = pre_co2_1\n",
    "    pre_co2s[i,2] = pre_co2_2\n",
    "    pre_co2s[i,3] = pre_co2_3\n",
    "    pre_co2s[i,4] = pre_co2_4\n",
    "    \n",
    "print(fused_co2.shape, pre_co2s.shape, all_refs.shape)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(fused_co2.shape[0]),fused_co2,np.mean(all_refs[1:,:],axis = 1))\n",
    "plt.ylabel(\"Co2 concentration in ppm\")\n",
    "plt.title(\"Sensor fusion results, belief functions with viterbi algorithm\")\n",
    "plt.legend(labels=[\"Fused result\",\"Mean of references\", \"Predicted co2 0\", \"Predicted co2 1\",\"Predicted co2 2\",\"Predicted co2 3\",\"Predicted co2 4\"])\n",
    "plt.xticks(np.array([0,L-1]), [data_time_0[1], data_time_0[-1]])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(fused_co2.shape[0]),fused_co2)\n",
    "plt.plot(np.arange(fused_co2.shape[0]),np.mean(all_refs[1:,:],axis = 1),np.mean(pre_co2s,axis = 1))\n",
    "plt.xticks(np.array([0,L-1]), [data_time_0[1], data_time_0[-1]])\n",
    "plt.ylabel(\"Co2 concentration in ppm\")\n",
    "plt.title(\"Sensor fusion results, belief functions with viterbi algorithm\")\n",
    "plt.legend(labels=[\"Fused result\",\"Mean of references\", \"Mean of predictions\"])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}